{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sound processing using Python\n",
    "*IMPRS - Using Python for Cognitive Science (2022). This tutorial is made by Noor Seijdel and is partly based on work by [Sophie Slaats](https://www.mpi.nl/people/slaats-sophie), and on  several [Pydub](https://github.com/jiaaro/pydub) tutorials*\n",
    "\n",
    "Welcome! In this module we will learn how to use Python for sound processing. Last week, we dicsussed Image Processing. This week, we will cover Sound Processing. \n",
    "\n",
    "After this session you will know:\n",
    "- How to open and save sound files and manipulate them using the PyDub package\n",
    "- How to split and splice sound files\n",
    "- How to append or mix audio from different files \n",
    "- How to change audio levels or apply simple effects such as filters \n",
    "\n",
    "All of these can be achieved using Pydub, a simple, well-designed Python module for audio manipulation. In the words of the PyDub authors:\n",
    "\"Pydub lets you do stuff to audio in a way that isn't stupid\". \n",
    "\n",
    "\n",
    "*For those who are interested we have added some resources for Using Praat in Python at the end of this tutorial. Note that this part is not mandatory.*\n",
    "\n",
    "\n",
    "##### 1.1 Installation and imports\n",
    "Following the installation guide, you have hopefully installed Pydub using pip, and ffmpeg using choco/brew. If not, please have a look at the installation manual. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also install a pip package in the current Jupyter kernel (uncomment the next lines)\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install simpleaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pydub import AudioSegment, silence, effects\n",
    "from pydub.playback import play\n",
    "# from matplotlib.pyplot import plot, show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this line of code if you can't add ffmpeg to your PATH (as per instructions)\n",
    "# doesn't hurt to add it ...\n",
    "AudioSegment.converter = \"C:\\\\Users\\\\noors\\\\ffmpeg\\\\bin\\\\ffmpeg.exe\"\n",
    "\n",
    "# Use the os module. Works for UNIX, Windows, MacOS...\n",
    "# e.g., to get working directory\n",
    "os.getcwd()\n",
    "\n",
    "# or change working directory\n",
    "# os.chdir(\"path\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2 Reading audio files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where are the sound files?\n",
    "sound_folder = \"E:\\\\Projects\\\\2021_audiovisual\\\\session2b-soundprocessing\\\\raw\"\n",
    "\n",
    "# load a sound file\n",
    "sound_path = os.path.join(sound_folder, \"left_right.wav\")\n",
    "print(sound_path)\n",
    "sound = AudioSegment.from_wav(sound_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as with the image files, every audio file you work with will have a number of characteristics associated with them, such as, channels, frame rate (or sample rate), sample width and more.\n",
    "\n",
    "'AudioSegment' has attributes like 'channels', 'dBFS', 'duration_seconds'.\n",
    "Let's see what that means.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sound.duration_seconds)\n",
    "\n",
    "# Or access several of them in one line\n",
    "# dBFS: decibels relative to full scale\n",
    "# full scale; maximum possible digital level\n",
    "print(sound.channels, sound.dBFS, sound.duration_seconds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color='green'>**Exercise 1**</font>  Find out what the frame rate and max volume of sound is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The frame rate or sampling rate says that this audio was recorded (sampled) with a sampling frequency of 44100. In other words, while recording this file we were capturing 44100 amplitudes every second. Thus, If we want to know the duration of the audio, we can also  divide the number of samples (frames) by the sampling-rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_snd = sound.frame_count()/sound.frame_rate\n",
    "print(duration_snd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to manipulate or change an audio file is by using\n",
    "\n",
    "`sound_edited = sound.set_ATTRIBUTENAME(x)`\n",
    "\n",
    "For example, you can change the number of channels (convert the file from stereo to mono) by calling `sound_mono = sound.set_channels(1)'\n",
    "\n",
    "<font color='green'>**Exercise 2**</font>  Try to change the frame rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_edited = ### YOUR CODE HERE\n",
    "print(sound_edited.frame_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay! So AudioSegment objects are immutable and support a number of operations. \n",
    "\n",
    "##### 1.3 Let's play the sound!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play a sound\n",
    "play(sound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.4 Visualize the sound\n",
    "A sound is a time-series, like EEG or MEG data. It is an array of samples with a specific value. PyDub can give us this so we can plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = sound.get_array_of_samples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns the raw audio data as an array of (numeric) samples. \n",
    "*Note: if the audio has multiple channels, the samples for each channel will be serialized – for example, stereo audio would look like [sample_1_L, sample_1_R, sample_2_L, sample_2_R, …].*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at the array\n",
    "#print(array)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot it! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we plot it. If you don't run in console, you have to type show() to actually open a window with the plot.\n",
    "plot(array)\n",
    "#show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This visualization is called the time-domain representation of a given signal. This shows us the loudness (amplitude) of sound wave changing with time. Here amplitude = 0 represents silence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.5 Saving audio files and changing the extension\n",
    "\n",
    "If you've made some changes to your audio files, or if they've got the wrong file extension, you can use PyDub to export and save them as new audio files.\n",
    "\n",
    "You can do this by using the .export() function on any instance of an AudioSegment you've created. The export() function takes two parameters, out_f, or the destination file path of your audio file and format, the format you'd like your new audio file to be. Both of these are strings. format is \"mp3\" by default so be sure to change it if you need.\n",
    "\n",
    "Let's start by saving the extension of our file to .mp3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the extension: wav to mp3\n",
    "# first: split the extension and the name using os.path.splitext\n",
    "# N.B.: the function os.path.split() splits the path to the folder from the filename.\n",
    "filename, extension = os.path.splitext(sound_path)\n",
    "\n",
    "# Export the sound to change the extension\n",
    "new_filename = os.path.join(sound_folder, filename) + \".mp3\"\n",
    "sound.export(new_filename, format=\"mp3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also remove it again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(new_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we can make a new folder to save our edited or changed audiofiles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_folder = \"E:\\\\Projects\\\\2021_audiovisual\\\\session2b-soundprocessing\\\\tmp\"\n",
    "if not os.path.isdir(new_folder): # Here we check if the folder already exists! If so, we do not have to make it again. \n",
    "   os.mkdir(new_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='green'>**Exercise 2:**</font>  Store the audio files in the new folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE\n",
    "# Hint: do you remember how to list all files in one folder?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we now know how to read in audio files, inspect their attributes, visualize them and export them (to different formats). Now let's have a look at manipulating your audio files! \n",
    "\n",
    "##### 1.6 Manipulating Audiofiles \n",
    "##### 1.6.1 Splitting and splicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split our audiofile in two on the basis of duration. \n",
    "\n",
    "Let's try to get the first half and the second half of our audiofile (note that Pydub works in milliseconds!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "halftime = (sound.duration_seconds / 2) * 1000\n",
    "first_half = sound[:halftime]\n",
    "second_half = sound[halftime:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did it work?\n",
    "\n",
    "<font color='green'>**Exercise 3:**</font>  Check if it worked by playing the two audiofiles: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6.2 Combining\n",
    "\n",
    "We can also combine multiple AudioSegment objects by concatenating them:  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate them\n",
    "wrong_order = second_half + first_half\n",
    "plot(wrong_order.get_array_of_samples())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or add silence in between:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silent_time = AudioSegment.silent(duration=2000)\n",
    "wrong_order_silence = second_half + silent_time + first_half\n",
    "\n",
    "plot(wrong_order_silence.get_array_of_samples())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play(wrong_order_silence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that any operation that combines multiple AudioSegment objects in any way will first ensure that they have the same number of channels, frame rate, sample rate, bit depth, etc. When these things do not match, the lower quality sound is modified to match the quality of the higher quality sound so that quality is not lost: mono is converted to stereo, bit depth and frame rate/sample rate are increased as needed. If you do not want this behavior, you may explicitly reduce the number of channels, bits, etc using the appropriate AudioSegment methods.\n",
    "\n",
    "\n",
    "##### 1.6.3 Splitting on the basis of silence\n",
    "\n",
    "But we can't just ADD silence -- we can also split the sound file on the basis of silence!\n",
    "Let's try it out on a more complicated sound file: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a sound file\n",
    "sound_path = os.path.join(sound_folder, \"HF_recording.wav\")\n",
    "print(sound_path)\n",
    "sound = AudioSegment.from_wav(sound_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play(sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = silence.split_on_silence(sound, min_silence_len=500, silence_thresh=-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so splitting this file gives you multiple segments, depending on the parameters `min_silence_len` and `silence_thresh`. \n",
    "\n",
    "Let's listen to the first segment:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "play(words[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<font color='green'>**Exercise 4 :**</font> What happens if we change the minimal silence length and the silence threshold? Try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.6.4 Changing the volume\n",
    "\n",
    "Are your audio files too loud or too quiet? You can make your AudioSegments louder or quieter by adding or subtracting integers. Let's make our wav file 4 decibels louders and 10 decibels quieter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_sound = words[0]\n",
    "# change the volume by a number of dBs\n",
    "louder = auto_sound[:] + 4\n",
    "lower = auto_sound[:] - 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And play them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "play(louder)\n",
    "play(lower)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to not confuse concatenation with volume change, you can also write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "louder = auto_sound.apply_gain(4)\n",
    "lower = auto_sound.apply_gain(-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, you might want to change the volume in comparison to a given value.\n",
    "This is always relative to the maximum volume; maximum = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(louder.dBFS)\n",
    "# say, we want the volume to be 6 dB lower than maximum; -6 dBFS\n",
    "target_volume = -6\n",
    "change = target_volume - louder.dBFS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is how much we need to change the volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(change)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change it:\n",
    "target_sound = auto_sound.apply_gain(change)\n",
    "play(target_sound)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other things you can do, such as play the sound backwards, change the speed or overlay different sounds:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra: funny stuff\n",
    "# reverse\n",
    "backwards = auto_sound.reverse()\n",
    "play(backwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the speed\n",
    "hasty = effects.speedup(auto_sound, playback_speed=1.5)\n",
    "play(hasty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fade-out\n",
    "faded = backwards.fade_in(1000).fade_out(1000)\n",
    "play(faded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay \n",
    "overlayed = target_sound.overlay(backwards)\n",
    "play(overlayed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### 1.7 Synthesizing Tones\n",
    "Aside from loading and processing audio files, Pydub can also synthesize new tones.\n",
    "These can be sine, square, or sawtooth waves, at any frequency. It can also generate white noise. Tones can be turned into AudioSegment and combined like regular audio files.\n",
    "In the following example, we’ll use the Sine class to generate sine tones for the first 15 intervals in the harmonic series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub.generators import Sine\n",
    "\n",
    "# Create an empty AudioSegment\n",
    "result = AudioSegment.silent(duration=0)\n",
    "# Loop over 0-14\n",
    "for n in range(15):\n",
    "    # Generate a sine tone with frequency 200 * n\n",
    "    gen = Sine(200 * n)\n",
    "    # AudioSegment with duration 200ms, gain -3\n",
    "    sine  = gen.to_audio_segment(duration=200).apply_gain(-3)\n",
    "    # Fade in / out\n",
    "    sine = sine.fade_in(50).fade_out(100)\n",
    "    # Append the sine to our result\n",
    "    result += sine\n",
    "# Play the result\n",
    "play(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*Notice how we use the += operator to append each 200ms sine tone to the end of our empty segment.*\n",
    "\n",
    "<font color='green'>**Exercise 5:**</font> Play around with synthesizing tones and make a nice short song (if you do not think this is fun and helps you develop your python skills, skip it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='yellow'>**Homework assignment**</font> \n",
    "\n",
    "We have three conditions: High Frequency (HF), Low Frequency (LF), and Non-Words (NW). All words for each condition are stored in one .wav file.\n",
    "Your task is to:\n",
    "- split the words on the silence\n",
    "- make sure they all have the same loudness\n",
    "- save them in a folder corresponding to their condition (folder names: HF, LF, NW)\n",
    "\n",
    "\n",
    "To help you, we have included a text file with information about the stimuli you are going to split (names & condition),\n",
    "and returned a dictionary named 'stimuli' with condition as key, and the word itself as value. You can use this dictionary to name the files you have to save.\n",
    "\n",
    "**Quick check: did Teun discuss dictionaries in Session 1? or did we run out of time?** If so, do not worry! I will post some code snippets to help you get to the solution without knowledge of dictionaries. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This piece of code is here to help you.\n",
    "\n",
    "import csv\n",
    "path_to_repository = \"E:\\\\Projects\\\\2021_audiovisual\\\\session2b-soundprocessing\"  # add your own path here!\n",
    "\n",
    "# It reads a text file with information about the stimuli you are going to split (names & condition),\n",
    "# and returns a dictionary named 'stimuli' with condition as key, and the word itself as value.\n",
    "# You can use this dictionary to name the files you have to save.\n",
    "stimuli_info = open(os.path.join(path_to_repository, \"lexdec_stimuli.txt\"))\n",
    "stimuli_reader = csv.reader(stimuli_info, delimiter=',')\n",
    "headers = next(stimuli_reader, None)\n",
    "\n",
    "# Create the dictionary\n",
    "stimuli = {}\n",
    "for stimulus in stimuli_reader:\n",
    "    if stimulus[2] not in stimuli.keys():\n",
    "        stimuli[stimulus[2]] = list()\n",
    "    stimuli[stimulus[2]].append(stimulus[3])\n",
    "\n",
    "# Put them in alphabetical order\n",
    "for condition, words in stimuli.items():\n",
    "    sort = sorted(words)\n",
    "    stimuli[condition] = sort\n",
    "\n",
    "# change the non-word condition name\n",
    "stimuli[\"NW\"] = stimuli.pop(\"none\")\n",
    "\n",
    "# Now you have the stimulus names. Let's take a look at the dictionary:\n",
    "print(stimuli)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### Some hints:\n",
    "1. Where are the stimuli?\n",
    "2. How loud do you want your stimuli to be? Store it in a variable\n",
    "3. Where do you want to save your files? Make separate folders for the conditions.\n",
    "4. Do you normalize the volume for the whole sequence or for separate words? Why (not)? Try it if you like :)\n",
    "5. You can check whether your splitting worked by playing the sound, or by printing the length of the resulting list\n",
    "6. Use the index of the word [in the list of words you get after splitting] to get the right text from the dictionary.\n",
    "7. Recall you can plot your results to see what you have done.\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='pink'>**BONUS**: Praat in Python</font> \n",
    "\n",
    "If you're interested in using Praat in Python, LET US KNOW! There are some options. \n",
    "This is not part of the tutorial, but we can help you set it up if you like. \n",
    "\n",
    "*Disclaimer: I have no experience with Praat so I will only help you find the relevant materials*\n",
    "\n",
    "\n",
    "In the next cells you will see some examples using **Parselmouth**, a Python library for the Praat software. \n",
    "From their [website](https://parselmouth.readthedocs.io/en/stable/): \n",
    "\n",
    "*\"Though other attempts have been made at porting functionality from Praat to Python, Parselmouth is unique in its aim to provide a complete and Pythonic interface to the internal Praat code. While other projects either wrap Praat’s scripting language or reimplementing parts of Praat’s functionality in Python, Parselmouth directly accesses Praat’s C/C++ code (which means the algorithms and their output are exactly the same as in Praat) and provides efficient access to the program’s data, but also provides an interface that looks no different from any other Python library.\n",
    "Please note that Parselmouth is currently in premature state and in active development. While the amount of functionality that is currently present is not huge, more will be added over the next few months. As such, feedback and possibly contributions are highly appreciated.\"* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## It is also possible to install libraries from your notebook directly. \n",
    "# Uncomment the next two lines if you want to try it out: \n",
    "\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install praat-parselmouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import parselmouth\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sound = parselmouth.Sound(\"E:\\\\Projects\\\\2021_audiovisual\\\\session2b-soundprocessing\\\\raw\\\\the_north_wind_and_the_sun.wav\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sound` is now a Parselmouth [Sound](../api_reference.rst#parselmouth.Sound) object, and we can access its values and other properties to plot them with the common `matplotlib` Python library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(sound.xs(), sound.values.T)\n",
    "plt.xlim([sound.xmin, sound.xmax])\n",
    "plt.xlabel(\"time [s]\")\n",
    "plt.ylabel(\"amplitude\")\n",
    "plt.show() # or plt.savefig(\"sound.png\"), or plt.savefig(\"sound.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38a22b065f140b1b194ec590c9ddb08b730ed9af161286fe62f6ab494c4ee990"
  },
  "kernelspec": {
   "display_name": "Rift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
